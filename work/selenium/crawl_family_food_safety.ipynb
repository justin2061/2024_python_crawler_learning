{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1f7f82-0ae3-44ef-adab-562e74fea656",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q selenium==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac9151c-bca7-48c3-9c98-b197379236fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q lxml==4.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f0f902-d0c3-4b93-a4d1-39968da2e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q beautifulsoup4==4.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc87866c-8f09-491f-aee0-7b0ecbeae6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mysql-connector-python==8.0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01a36ee-3269-41a2-b717-bd9a87b63f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sqlalchemy==1.4.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d156e7e-65f6-4085-be42-6ee7710a8938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q backoff==2.1.2\n",
    "import backoff\n",
    "backoff.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2719d3f3-6348-4e98-ac29-d3c565aedf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5933a796-1c0c-4b35-b1f6-a92d15935c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b7296a-87f9-428e-9c69-44de3a2e120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import selenium\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "# import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import backoff\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from logging import handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c00f81-53e6-4bbf-88c2-f32aa0deda36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 17:24:25 Asia [3038962473] INFO [16] paper_main logger ready...\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('paper_main')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "log_format = logging.Formatter('%(asctime)s [%(module)s] %(levelname)s [%(lineno)d] %(message)s', '%Y-%m-%d %H:%M:%S %Z')\n",
    "\n",
    "th = handlers.TimedRotatingFileHandler(filename='app.log', when='D', backupCount=7, encoding='utf-8')\n",
    "th.setFormatter(log_format)\n",
    "th.setLevel(logging.INFO)\n",
    "logger.addHandler(th)\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(log_format)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info('paper_main logger ready...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a02882-067a-42f1-94ff-779ba30db9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = 'prints'\n",
    "db_passwd = 'prints78909!'\n",
    "db_name = 'kol_radar'\n",
    "tbl_name = 'paper_main'\n",
    "db_ip = '172.104.169.34'\n",
    "engine = create_engine(f'mysql+mysqlconnector://{db_user}:{db_passwd}@{db_ip}:3306/{db_name}')\n",
    "cnx = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876b9958-9d12-4cd2-ba6b-eb8e358279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_list(key_id=0):\n",
    "    keyword_query = cnx.execute(f'SELECT * FROM `key_prints` where parent_key_id = {key_id}')\n",
    "    keywords_dict = [dict(i) for i in keyword_query]\n",
    "    # print(keywords_dict)\n",
    "    return keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12664bf1-f9c6-4b25-8fd5-3af30d845823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ua():\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'\n",
    "    return user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a1a84c-d37e-4a32-a1ba-7d920312f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_sleep(min=1, max=12):\n",
    "    sleep_time = random.randint(min,max)\n",
    "    logger.info(f'sleep time: {sleep_time}')\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6645023e-0017-413d-903e-f8b7d2fe8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo,\n",
    "                        Exception, \n",
    "                      max_time=10)\n",
    "def chrome_init():\n",
    "    chrome_opt = webdriver.ChromeOptions()\n",
    "    chrome_opt.add_argument('--headless')\n",
    "    chrome_opt.add_argument('--no-sandbox')\n",
    "    chrome_opt.add_argument('--ignore-ssl-errors=yes')\n",
    "    chrome_opt.add_argument('--ignore-certificate-errors')\n",
    "    chrome_opt.add_argument(f'user-agent={set_ua()}')\n",
    "    chrome_opt.add_argument(\"--incognito\")  # 使用無痕模式。用 selenium開瀏覽器已經很乾淨了，但疑心病重的可以用一下\n",
    "    try:\n",
    "        driver = webdriver.Remote(\n",
    "            command_executor='http://selenium-hub:4444/wd/hub',\n",
    "            options=chrome_opt\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f'chrome init error: {e}')\n",
    "        raise Exception(e)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d92acb-a6f4-475a-9da2-3b140e07792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_home_page(url, driver):\n",
    "    driver.get(url)\n",
    "    title = driver.title\n",
    "    logger.info(title)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    driver.get_screenshot_as_file(\"論文全文資料庫.png\")\n",
    "    ccd = ''\n",
    "    if len(driver.current_url) > 0:\n",
    "        try:\n",
    "            ccd = re.findall(r'ccd=(.*?)/', driver.current_url)[0]\n",
    "        except:\n",
    "            logger.error(f'driver.current_url: {driver.current_url}')\n",
    "    little_sleep(1,3)\n",
    "    return ccd, driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e8f768-c777-494e-905a-f099115d5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_keyword_search_page(driver):\n",
    "    try:\n",
    "        # 正常\n",
    "        driver.find_element(By.XPATH, '//a[@title=\"指令查詢\"]').click()\n",
    "        driver.get_screenshot_as_file(\"指令查詢.png\")\n",
    "        little_sleep(1,3)\n",
    "    except:\n",
    "        driver.get_screenshot_as_file(\"keyword_search_page_ERROR.png\")\n",
    "        img_element = driver.find_element(By.XPATH, '/html/body/div/form/div[1]/img')\n",
    "        logger.error(f'ERR: {img_element}')\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9919e59e-795f-4c46-98dd-a7c1102734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = '\"汽車\" or \"家庭與社區\" or \"房地產\" or \"工商業\" or \"美妝與個人護理\" or \"場所與禮品\" or \"網際網路與電信\" or \"家居與園藝\" or \"食品與雜貨\" or \"保健\" or \"財經\" or \"藝術與娛樂\" or \"運動與健身\" or \"興趣與休閒\" or \"工作與教育\" or \"旅遊\" or \"法律與政府\" or \"電腦與消費性電子產品\" or \"餐飲與夜生活\" or \"服飾\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0787fb4b-9447-4fa1-b43d-590ad1ca34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search_result(keywords, driver):\n",
    "    search_result_count_xpath = '//*[@id=\"bodyid\"]/form/div/table/tbody/tr[1]/td[2]/table/tbody/tr[4]/td/div[1]/table/tbody/tr[2]/td/table[2]/tbody/tr[2]/td[2]/span[2]'\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"ysearchinput0\"]').send_keys(my_keys)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"gs32search\"]').click()\n",
    "    search_result_count_element = WebDriverWait(driver, timeout=120).until(lambda d: d.find_element(By.XPATH, search_result_count_xpath))\n",
    "    driver.get_screenshot_as_file(\"指令查詢_result.png\")\n",
    "    total_count = 0\n",
    "    if search_result_count_element is not None:\n",
    "        total_count = search_result_count_element.text\n",
    "    # ccd = re.findall(r'ccd=(.*?)/', driver.current_url)[0]\n",
    "    little_sleep(1,3)\n",
    "    return total_count, driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac10837e-7053-4f7c-bd0e-a814a2667dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paper_html(page_source):\n",
    "    # soup = BeautifulSoup(driver.page_source)\n",
    "    soup = BeautifulSoup(page_source, features=\"lxml\")\n",
    "    page_static_url=student=student_en=paper_title=paper_title_en=advisor=advisor_en=exam_committee=exam_committee_en=exam_date=degree_category=school=department=phylum=paper_class=paper_type=pub_year=graduaction_year=lang=paper_page=keywords_tw=keywords_en=abstract_note=abstract_note_en=directory=references=paper_paper=qrcode= None\n",
    "\n",
    "    # 論文基本資料\n",
    "    tbody = soup.find('table',{'id':'format0_disparea'})\n",
    "    if tbody is None:\n",
    "        driver.get_screenshot_as_file('tbody_none.png')\n",
    "        raise Exception(f'fetch tbody is None, page source size: {len(page_source)}')\n",
    "\n",
    "    # 連結網址\n",
    "    page_static_url = tbody.find('input',{'id':'fe_text1'})['value']\n",
    "    logger.info(f'連結網址： {page_static_url}')\n",
    "\n",
    "    # 研究生\n",
    "    for element in tbody.select('tr'):\n",
    "        if '研究生' in element.text:\n",
    "            student = element.find('a').text\n",
    "            break    \n",
    "    # print('研究生:', student)\n",
    "\n",
    "    # 研究生_外文\n",
    "    for element in tbody.select('tr'):\n",
    "        if '研究生(外文)' in element.text:\n",
    "            student_en = element.find('a').text\n",
    "            break    \n",
    "    # print('研究生_外文:', student)\n",
    "\n",
    "    # 論文名稱\n",
    "    for element in tbody.select('tr'):\n",
    "        if '論文名稱' in element.text:\n",
    "            paper_title = element.find('td').text\n",
    "            break    \n",
    "    # print('論文名稱:', paper_title)\n",
    "\n",
    "    # 論文名稱_外文\n",
    "    for element in tbody.select('tr'):\n",
    "        if '論文名稱(外文)' in element.text:\n",
    "            paper_title_en = element.find('td').text\n",
    "            break   \n",
    "    # print('論文名稱_外文:', paper_title_en)\n",
    "\n",
    "    # 指導教授\n",
    "    for element in tbody.select('tr'):\n",
    "        if '指導教授' in element.text:\n",
    "            advisor = element.find('td').text\n",
    "            break   \n",
    "    # print('指導教授:', advisor)\n",
    "\n",
    "    # 指導教授_外文\n",
    "    for element in tbody.select('tr'):\n",
    "        if '指導教授(外文)' in element.text:\n",
    "            advisor_en = element.find('td').text\n",
    "            break   \n",
    "    # print('指導教授_外文:', advisor_en)\n",
    "\n",
    "    # 學位類別\n",
    "    for element in tbody.select('tr'):\n",
    "        if '學位類別' in element.text:\n",
    "            degree_category = element.find('td').text\n",
    "            break   \n",
    "    # print('學位類別:', degree_category)\n",
    "\n",
    "    # 校院名稱\n",
    "    for element in tbody.select('tr'):\n",
    "        if '校院名稱' in element.text:\n",
    "            school = element.find('td').text\n",
    "            break   \n",
    "    # print('校院名稱:', school)\n",
    "\n",
    "    # 系所名稱\n",
    "    for element in tbody.select('tr'):\n",
    "        if '系所名稱' in element.text:\n",
    "            department = element.find('td').text\n",
    "            break   \n",
    "    # print('系所名稱:', department)\n",
    "\n",
    "    # 學門\n",
    "    for element in tbody.select('tr'):\n",
    "        if '學門' in element.text:\n",
    "            phylum = element.find('td').text\n",
    "            break   \n",
    "    # print('學門:', phylum)\n",
    "\n",
    "    # 學類\n",
    "    for element in tbody.select('tr'):\n",
    "        if '學類' in element.text:\n",
    "            paper_class = element.find('td').text\n",
    "            break   \n",
    "    # print('學類:', paper_class)\n",
    "\n",
    "    # 論文出版年\n",
    "    for element in tbody.select('tr'):\n",
    "        if '論文出版年' in element.text:\n",
    "            pub_year = element.find('td').text\n",
    "            break   \n",
    "    # print('論文出版年:', pub_year)\n",
    "\n",
    "    # 畢業學年度\n",
    "    for element in tbody.select('tr'):\n",
    "        if '畢業學年度' in element.text:\n",
    "            pub_year = element.find('td').text\n",
    "            break   \n",
    "    # print('畢業學年度:', pub_year)\n",
    "\n",
    "    # 語文別\n",
    "    for element in tbody.select('tr'):\n",
    "        if '語文別' in element.text:\n",
    "            lang = element.find('td').text\n",
    "            break   \n",
    "    # print('語文別:', lang)\n",
    "\n",
    "    # 論文頁數\n",
    "    for element in tbody.select('tr'):\n",
    "        if '論文頁數' in element.text:\n",
    "            paper_page = element.find('td').text\n",
    "            if paper_page == '':\n",
    "                paper_page = None\n",
    "            if paper_page is not None:\n",
    "                paper_page = int(paper_page)\n",
    "            break   \n",
    "    # print('論文頁數:', paper_page)\n",
    "\n",
    "    # 中文關鍵詞\n",
    "    for element in tbody.select('tr'):\n",
    "        if '中文關鍵詞' in element.text:\n",
    "            keywords_tw = element.find('td').text\n",
    "            break   \n",
    "    # print('中文關鍵詞:', keywords_tw)\n",
    "\n",
    "    # 外文關鍵詞\n",
    "    for element in tbody.select('tr'):\n",
    "        if '外文關鍵詞' in element.text:\n",
    "            keywords_en = element.find('td').text\n",
    "            break   \n",
    "    # print('外文關鍵詞:', keywords_en)\n",
    "\n",
    "    # 被引用\n",
    "    for element in tbody.select('tr'):\n",
    "        if '相關次數' in element.text:\n",
    "            refed = element.findAll('li')[0].text\n",
    "            refed = re.sub('被引用:','',refed)\n",
    "            break   \n",
    "    # print('被引用:', refed)\n",
    "\n",
    "    # 點閱\n",
    "    for element in tbody.select('tr'):\n",
    "        if '相關次數' in element.text:\n",
    "            click = element.findAll('li')[1].text\n",
    "            break   \n",
    "    # print('點閱:', click)\n",
    "\n",
    "    # 下載\n",
    "    for element in tbody.select('tr'):\n",
    "        if '相關次數' in element.text:\n",
    "            download_times = element.findAll('li')[3].text\n",
    "            download_times = re.sub('下載:','',download_times)\n",
    "            break   \n",
    "    # print('下載:', download_times)\n",
    "\n",
    "    # 書目收藏\n",
    "    for element in tbody.select('tr'):\n",
    "        if '相關次數' in element.text:\n",
    "            collection = element.findAll('li')[4].text\n",
    "            collection = re.sub('書目收藏:','',collection)\n",
    "            break   \n",
    "    # print('書目收藏:', collection)\n",
    "\n",
    "    stdncl2 = soup.find_all('td',{'class':'stdncl2'})\n",
    "    # print(f'stdncl2 size: [{len(stdncl2)}]')\n",
    "    # for each_info in stdncl2:\n",
    "    #     print(f'info: {each_info.text}')\n",
    "    # print(f'摘要: {stdncl2[0].text}')\n",
    "    # print(f'摘要_en: {stdncl2[1].text}')\n",
    "    # print(f'目次: {stdncl2[2].text}')\n",
    "    # print(f'參考文獻: {stdncl2[3].text}')\n",
    "\n",
    "    # 摘要\n",
    "    try:\n",
    "        # abstract_note = soup.find('td',{'class':'stdncl2'}).text\n",
    "        abstract_note = stdncl2[0].text if len(stdncl2) > 1 and stdncl2[0] is not None else ''\n",
    "    except:\n",
    "        abstract_note = ''\n",
    "    # print('摘要：', abstract_note)\n",
    "\n",
    "    # 摘要_en\n",
    "    try:\n",
    "        # abstract_note_en = soup.find('td',{'class':'stdncl2'}).text\n",
    "        abstract_note_en = stdncl2[1].text if len(stdncl2) >= 2 and stdncl2[1] is not None else ''\n",
    "    except:\n",
    "        abstract_note_en = ''\n",
    "    # print(f'摘要_en：{abstract_note_en}')\n",
    "\n",
    "    # 目次\n",
    "    try:\n",
    "        directory = stdncl2[2].text if len(stdncl2) >= 3 and stdncl2[2] is not None else ''\n",
    "    except:\n",
    "        directory = ''\n",
    "\n",
    "    # 參考文獻\n",
    "    try:\n",
    "        references = stdncl2[3].text if len(stdncl2) >= 4 and stdncl2[3] is not None else ''\n",
    "    except:\n",
    "        references = ''\n",
    "\n",
    "    # 口試委員\n",
    "    for element in tbody.select('tr'):\n",
    "        if '口試委員' in element.text:\n",
    "            exam_committee = element.find('td').text if element.find('td') is not None else ''\n",
    "            break\n",
    "        # print('口試委員:', exam_committee)\n",
    "\n",
    "    # 口試委員_外文\n",
    "    exam_committee_en = ''\n",
    "    for element in tbody.select('tr'):\n",
    "        if '口試委員(外文)' in element.text:\n",
    "            exam_committee_en = element.find('td').text\n",
    "            break   \n",
    "        # print('口試委員_外文:', exam_committee_en)\n",
    "\n",
    "    # 口試日期\n",
    "    for element in tbody.select('tr'):\n",
    "        if '口試日期' in element.text:\n",
    "            exam_date = element.find('td').text\n",
    "            print(f'fetch exam date: {exam_date}, type: {type(exam_date)}')\n",
    "            if len(exam_date) == 0:\n",
    "                exam_date = None\n",
    "            if exam_date is not None:\n",
    "                exam_date = datetime.strptime(exam_date, '%Y-%m-%d')\n",
    "            break\n",
    "        if exam_date is not None:\n",
    "            logger.info(f'口試日期: {exam_date}, type: {type(exam_date)}')\n",
    "\n",
    "    #論文種類\n",
    "    for elememt in tbody.select('tr'):\n",
    "        if '論文種類' in element.text:\n",
    "            paper_type = element.find('td').text\n",
    "            break\n",
    "        # print(f'論文種類: {paper_type}')\n",
    "\n",
    "    # 引用\n",
    "    refer_html = str(soup.find('div',{'style':'padding:10px;text-align:left;'}))\n",
    "    \n",
    "    paper = {\n",
    "        'paper_url': page_static_url,\n",
    "        'author': student,\n",
    "        'author_en': student_en,\n",
    "        'title': paper_title,\n",
    "        'title_en': paper_title_en,\n",
    "        'advisor': advisor,\n",
    "        'advisor_en': advisor_en,\n",
    "        'interviewer': exam_committee,\n",
    "        'interviewer_en': exam_committee_en,\n",
    "        'exam_date': exam_date,\n",
    "        'paper_type': degree_category,\n",
    "        'school': school,\n",
    "        'department_lv1': department,\n",
    "        'department_lv2': phylum,\n",
    "        'department_lv3': paper_class,\n",
    "        'paper_type': paper_type,\n",
    "        'publish_year': pub_year,\n",
    "        'graduaction_year': graduaction_year, #畢業學年度\n",
    "        'lang': lang, #語文別\n",
    "        'paper_page': paper_page, #論文頁數\n",
    "        'paper_keyword_cn': keywords_tw,\n",
    "        'paper_keyword_en': keywords_en,\n",
    "        'paper_summary': abstract_note,\n",
    "        'paper_summary_en': abstract_note_en, #外文摘要\n",
    "        'directory': directory, #目次\n",
    "        # '紙本論文': paper_paper,\n",
    "        # 'QRCode': qrcode,\n",
    "        'quote': references,\n",
    "        'refer_html': refer_html,\n",
    "        'page_source': page_source\n",
    "    }\n",
    "    return paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0e26b3-4cb3-4f0e-966c-d566e14506f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo,\n",
    "                      (selenium.common.exceptions.UnexpectedAlertPresentException, \n",
    "                        Exception, \n",
    "                        mysql.connector.errors.OperationalError),\n",
    "                      max_time=10)\n",
    "def scrape_each_paper(search_result_count, ccd, driver, start_num=1):\n",
    "    curr_page_num = 0\n",
    "    search_result_count = int(search_result_count)\n",
    "    if search_result_count > 0:\n",
    "        # paper_df = pd.DataFrame()\n",
    "        insert_sql = text(\"\"\"INSERT INTO `paper_main` (`paper_url`, `author`, `author_en`, `title`, `title_en`, `advisor`, `advisor_en`, `interviewer`, `interviewer_en`, `exam_date`, `paper_type`, `school`, `department_lv1`, `department_lv2`, `department_lv3`, `publish_year`, `graduaction_year`, `lang`, `paper_page`, `paper_keyword_cn`, `paper_keyword_en`, `paper_summary`, `paper_summary_en`, `directory`, `quote`, `refer_html`, `page_source`) VALUES\n",
    "(:paper_url, :author, :author_en, :title, :title_en, :advisor, :advisor_en, :interviewer, :interviewer_en, :exam_date, :paper_type, :school, :department_lv1, :department_lv2, :department_lv3, :publish_year, :graduaction_year, :lang, :paper_page, :paper_keyword_cn, :paper_keyword_en, :paper_summary, :paper_summary_en, :directory, :quote, :refer_html, :page_source);\n",
    "\"\"\")\n",
    "        update_sql = text(\"\"\"\n",
    "            update `paper_main`\n",
    "            set \n",
    "            `author` = :author,\n",
    "            `author_en` = :author_en,\n",
    "            `title` = :title,\n",
    "            `title_en` = :title_en,\n",
    "            `advisor` = :advisor,\n",
    "            `advisor_en` = :advisor_en,\n",
    "            `interviewer` = :interviewer,\n",
    "            `interviewer_en` = :interviewer_en,\n",
    "            `exam_date` = :exam_date,\n",
    "            `paper_type` = :paper_type,\n",
    "            `school` = :school,\n",
    "            `department_lv1` = :department_lv1,\n",
    "            `department_lv2` = :department_lv2,\n",
    "            `department_lv3` = :department_lv3,\n",
    "            `publish_year` = :publish_year,\n",
    "            `graduaction_year` = :graduaction_year,\n",
    "            `lang` = :lang,\n",
    "            `paper_page` = :paper_page,\n",
    "            `paper_keyword_cn` = :paper_keyword_cn,\n",
    "            `paper_keyword_en` = :paper_keyword_en,\n",
    "            `paper_summary` = :paper_summary,\n",
    "            `paper_summary_en` = :paper_summary_en,\n",
    "            `directory` = :directory,\n",
    "            `quote` = :quote,\n",
    "            `refer_html` = :refer_html,\n",
    "            `page_source` = :page_source\n",
    "            where `paper_url` = :paper_url\n",
    "        \"\"\")\n",
    "        count_sql = text(\"\"\"select count(*) as cnt from `paper_main` where `paper_url` = :paper_url\"\"\")\n",
    "        i = start_num\n",
    "        for i in range(1, search_result_count):\n",
    "            if i % 200 == 0:\n",
    "                ccd, driver = crawl_home_page(url, driver)\n",
    "                print(f'new ccd: {ccd}, curr url: {driver.current_url}')\n",
    "                driver = keyword_search_page(driver)\n",
    "                total_count, driver = keyword_search_result(my_keys, driver)\n",
    "                little_sleep(1,3)\n",
    "            logger.info(f'ccd: {ccd}')\n",
    "            if ccd is None:\n",
    "                ccd, driver = crawl_home_page(url, driver)\n",
    "            page_url = f'https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd={ccd}/record?r1={i}&h1=0'\n",
    "            logger.info(f'page url: {page_url}')\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "                paper = parse_paper_html(driver.page_source)\n",
    "                # paper_df = paper_df.append(paper, ignore_index=True)\n",
    "                # paper_df = pd.DataFrame(paper)\n",
    "                count_result = cnx.execute(count_sql, **paper)\n",
    "                count_dict = [dict(i) for i in count_result]\n",
    "                cnt = int(count_dict[0]['cnt'])\n",
    "                logger.info(f'[{i}]page url: {page_url}, count: {cnt}')\n",
    "                if cnt == 0:\n",
    "                    cnx.execute(insert_sql, **paper)\n",
    "                else:\n",
    "                    cnx.execute(update_sql, **paper)\n",
    "            except Exception as e:\n",
    "                logger.error(f'[{i}]page: {page_url} error')\n",
    "                logger.error(e)\n",
    "                driver.get_screenshot_as_file(f\"page_{driver.title}_error.png\")\n",
    "                # paper_df.to_csv(f'error/{page_url}_error.csv')\n",
    "            finally:\n",
    "                curr_page_num = i\n",
    "                little_sleep(3,12)\n",
    "            logger.info('='*11)\n",
    "    return curr_page_num, driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326b92bc-1707-4bd7-964d-7d8bc4fdb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_paper_pages(keywords, curr_page_num, driver):\n",
    "    try:\n",
    "        driver = go_keyword_search_page(driver)\n",
    "        total_count, driver = keyword_search_result(keywords, driver)\n",
    "        logger.info(f'結果筆數: {total_count}, ccd: {ccd}')\n",
    "        curr_page_num, driver = scrape_each_paper(total_count, ccd, driver, curr_page_num)\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f80e9d0-49f4-4eb3-ad95-1fc26aef8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 17:24:32 Asia [985876430] INFO [2] url: https://ndltd.ncl.edu.tw/\n"
     ]
    }
   ],
   "source": [
    "url = 'https://ndltd.ncl.edu.tw/'\n",
    "logger.info(f'url: {url}')\n",
    "# driver = None\n",
    "search_paper_result = {}\n",
    "curr_page_num = 1\n",
    "total_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0081af65-2df9-4c24-90f9-423b79090723",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 17:24:41 Asia [3831567472] INFO [4] 臺灣博碩士論文知識加值系統：自由的博碩士學位論文全文資料庫 (現在位置：首頁)\n",
      "2022-08-05 17:24:49 Asia [1540640465] INFO [3] sleep time: 3\n",
      "2022-08-05 17:24:52 Asia [3014959867] INFO [4] https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/login?jstimes=1&loadingjs=1&o=dwebmge&ssoauth=1&cache=1659720276928\n",
      "2022-08-05 17:24:53 Asia [1540640465] INFO [3] sleep time: 3\n",
      "2022-08-05 17:25:01 Asia [1540640465] INFO [3] sleep time: 2\n",
      "2022-08-05 17:25:03 Asia [3014959867] INFO [9] 結果筆數:  160583 , ccd: wGo8a0\n",
      "2022-08-05 17:25:03 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:03 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=1&h1=0\n",
      "2022-08-05 17:25:04 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/pm2by2\n",
      "2022-08-05 17:25:04 Asia [665092158] INFO [67] [1]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=1&h1=0, count: 1\n",
      "2022-08-05 17:25:05 Asia [1540640465] INFO [3] sleep time: 11\n",
      "2022-08-05 17:25:16 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:25:16 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:16 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=2&h1=0\n",
      "2022-08-05 17:25:17 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/pf924u\n",
      "2022-08-05 17:25:17 Asia [665092158] INFO [67] [2]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=2&h1=0, count: 1\n",
      "2022-08-05 17:25:17 Asia [1540640465] INFO [3] sleep time: 3\n",
      "2022-08-05 17:25:20 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:25:20 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:20 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=3&h1=0\n",
      "2022-08-05 17:25:21 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/36j8qd\n",
      "2022-08-05 17:25:21 Asia [665092158] INFO [67] [3]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=3&h1=0, count: 1\n",
      "2022-08-05 17:25:21 Asia [1540640465] INFO [3] sleep time: 10\n",
      "2022-08-05 17:25:32 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:25:32 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:32 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=4&h1=0\n",
      "2022-08-05 17:25:32 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/8ea73q\n",
      "2022-08-05 17:25:32 Asia [665092158] INFO [67] [4]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=4&h1=0, count: 1\n",
      "2022-08-05 17:25:33 Asia [1540640465] INFO [3] sleep time: 12\n",
      "2022-08-05 17:25:45 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:25:45 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:45 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=5&h1=0\n",
      "2022-08-05 17:25:46 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/vds3nq\n",
      "2022-08-05 17:25:46 Asia [665092158] INFO [67] [5]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=5&h1=0, count: 1\n",
      "2022-08-05 17:25:47 Asia [1540640465] INFO [3] sleep time: 7\n",
      "2022-08-05 17:25:54 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:25:54 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:25:54 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=6&h1=0\n",
      "2022-08-05 17:25:55 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/64yqcf\n",
      "2022-08-05 17:25:55 Asia [665092158] INFO [67] [6]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=6&h1=0, count: 1\n",
      "2022-08-05 17:25:55 Asia [1540640465] INFO [3] sleep time: 11\n",
      "2022-08-05 17:26:06 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:26:06 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:26:06 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=7&h1=0\n",
      "2022-08-05 17:26:07 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/g5dxr3\n",
      "2022-08-05 17:26:07 Asia [665092158] INFO [67] [7]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=7&h1=0, count: 1\n",
      "2022-08-05 17:26:07 Asia [1540640465] INFO [3] sleep time: 8\n",
      "2022-08-05 17:26:15 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:26:15 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:26:15 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=8&h1=0\n",
      "2022-08-05 17:26:16 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/z69s2w\n",
      "2022-08-05 17:26:16 Asia [665092158] INFO [67] [8]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=8&h1=0, count: 1\n",
      "2022-08-05 17:26:17 Asia [1540640465] INFO [3] sleep time: 5\n",
      "2022-08-05 17:26:22 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:26:22 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:26:22 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=9&h1=0\n",
      "2022-08-05 17:26:22 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/kupjjm\n",
      "2022-08-05 17:26:23 Asia [665092158] INFO [67] [9]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=9&h1=0, count: 1\n",
      "2022-08-05 17:26:23 Asia [1540640465] INFO [3] sleep time: 9\n",
      "2022-08-05 17:26:32 Asia [665092158] INFO [80] ===========\n",
      "2022-08-05 17:26:32 Asia [665092158] INFO [54] ccd: wGo8a0\n",
      "2022-08-05 17:26:32 Asia [665092158] INFO [58] page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=10&h1=0\n",
      "2022-08-05 17:26:33 Asia [1296822138] INFO [14] 連結網址： https://hdl.handle.net/11296/4zz3m7\n",
      "2022-08-05 17:26:33 Asia [665092158] INFO [67] [10]page url: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=wGo8a0/record?r1=10&h1=0, count: 1\n",
      "2022-08-05 17:26:33 Asia [1540640465] INFO [3] sleep time: 12\n",
      "2022-08-05 17:26:39 Asia [3014959867] INFO [35] driver: <selenium.webdriver.remote.webdriver.WebDriver (session=\"b2009a1ac8c437668abf379eb97d4652\")>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m total_count, driver \u001b[38;5;241m=\u001b[39m keyword_search_result(my_keys, driver)\n\u001b[1;32m      9\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m結果筆數: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ccd: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mccd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m curr_page_num, driver \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_each_paper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mccd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_page_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m search_paper_result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_words\u001b[39m\u001b[38;5;124m'\u001b[39m: my_keys,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_count\u001b[39m\u001b[38;5;124m'\u001b[39m: total_count,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurr_page_num\u001b[39m\u001b[38;5;124m'\u001b[39m : curr_page_num\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m curr_page_num \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m total_count:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[38;5;241m=\u001b[39m (tries \u001b[38;5;241m==\u001b[39m max_tries_value)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mscrape_each_paper\u001b[0;34m(search_result_count, ccd, driver, start_num)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;66;03m# paper_df.to_csv(f'error/{page_url}_error.csv')\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m             curr_page_num \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m---> 79\u001b[0m             \u001b[43mlittle_sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m11\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m curr_page_num, driver\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mlittle_sleep\u001b[0;34m(min, max)\u001b[0m\n\u001b[1;32m      2\u001b[0m sleep_time \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mmin\u001b[39m,\u001b[38;5;28mmax\u001b[39m)\n\u001b[1;32m      3\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    driver = chrome_init()\n",
    "    ccd, driver = crawl_home_page(url, driver)\n",
    "    logger.info(driver.current_url)\n",
    "    while True:\n",
    "        try:\n",
    "            driver = go_keyword_search_page(driver)\n",
    "            total_count, driver = keyword_search_result(my_keys, driver)\n",
    "            logger.info(f'結果筆數: {total_count}, ccd: {ccd}')\n",
    "            curr_page_num, driver = scrape_each_paper(total_count, ccd, driver, curr_page_num)\n",
    "            search_paper_result = {\n",
    "                'key_words': my_keys,\n",
    "                'total_count': total_count,\n",
    "                'curr_page_num' : curr_page_num\n",
    "            }\n",
    "            if curr_page_num >= total_count:\n",
    "                break;\n",
    "        except Exception as e:\n",
    "            logger.error(f'curr page num:{curr_page_num}, total count: {total_count}, keywords: {my_keys}')\n",
    "            logger.error(e)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    # search_paper_result = {\n",
    "    #     'key_words': my_keys,\n",
    "    #     'total_count': total_count,\n",
    "    #     'curr_page_num' : curr_page_num\n",
    "    # }\n",
    "    logger.error(e)\n",
    "    # logger.error(f'search paper result: {search_paper_result}')\n",
    "finally:\n",
    "    if driver is not None:\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        logger.info(f'driver: {driver}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ca502-51af-4bed-b240-8be329267781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
